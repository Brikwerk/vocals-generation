{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Theory\n",
    "\n",
    "The combined model is trained with the triple criterion*:\n",
    "\n",
    "$\\mathcal{L} = \\mathcal{L}_{prior} + \\mathcal{L}_{llike}^{Dis_l} + \\mathcal{L}_{GAN}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\mathcal{L}_{prior} = D_{KL}(q(z|x) \\Vert p(z))$\n",
    "\n",
    "$\\mathcal{L}_{GAN} = \\log(Dis(x)) + \\log(1-Dis(Dec(z))) + \\log(1-Dis(Dec(Enc(x))))$            \n",
    "\n",
    "$\\mathcal{L}_{llike}^{Dis_l} = -\\mathbb{E}_{q(z|x)}[\\log p(Dis_l (x)|z)]$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "$x$ is a training sample and $z \\sim p(z)$\n",
    "(Dis = discriminator; Gen = Decoder)\n",
    "\n",
    "In addition, for $\\mathcal{L}_{GAN}$, $x = Dec(z)$ with $z \\sim p(z)$\n",
    "\n",
    "$\\mathcal{L}_{GAN}$ is the style error;\n",
    "$\\mathcal{L}_{llike}^{Dis_l}$ is the reconstruction (content)  error\n",
    "\n",
    "Optimise decoder wrt $\\mathcal{L}_{GAN}$\n",
    "\n",
    "---\n",
    "\\*  The authors do not explicitly do this, see the gradient updates section below. (They seem to use this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mathcal{L}_{llike}^{Dis_l}$  (learned distance/ Reconstruction Error)\n",
    "\n",
    "$Dis_l(x)$ is the hidden representation of the $l$ th layer of the discriminator\n",
    "\n",
    "Uses a Gaussian observation model for $Dis_l(x)$\n",
    "- Mean: $Dis_l(\\tilde x)$ where $\\tilde x \\sim Dec(z)$ is the sample from the decoder of $x$.\n",
    "- Identity covariance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Practice\n",
    "\n",
    "- Do not update all network parameters wrt. the combined loss\n",
    "    * The Discriminator should not minimise $\\mathcal{L}_{llike}^{Dis_l}$ (collapses discriminator to 0)\n",
    "    * Do not backpropagate the error signal from $\\mathcal{L}_{GAN}$ to the Encoder\n",
    "\n",
    "- Use a parameter $\\gamma$ to weight the ability to reconstruct vs. fooling the discriminator\n",
    "    * not applied to the entire model\n",
    "    * weighting only applied when updating the parameters of the decoder.\n",
    "    * $\\theta_{Dec} \\stackrel{+}\\leftarrow - \\nabla_{\\theta_{Dec}} (\\gamma \\mathcal{L}_{llike}^{Dis_l} - \\mathcal{L}_{GAN})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating gradients\n",
    "\n",
    "1. $\\theta_{Enc} \\stackrel{+}\\leftarrow - \\nabla_{\\theta_{Enc}} (\\mathcal{L}_{prior} + \\mathcal{L}_{llike}^{Dis_l})$\n",
    "2. $\\theta_{Dec} \\stackrel{+}\\leftarrow - \\nabla_{\\theta_{Dec}} (\\gamma \\mathcal{L}_{llike}^{Dis_l} - \\mathcal{L}_{GAN})$\n",
    "3. $\\theta_{Dis} \\stackrel{+}\\leftarrow - \\nabla_{\\theta_{Dis}} \\mathcal{L}_{GAN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. After encoder runs, calculate $\\mathcal{L}_{prior}$\n",
    "\n",
    "2. After decoder runs, (and maybe the disc), calculate the layer-wise disc loss,$\\mathcal{L}_{llike}^{Dis_l}$\n",
    "\n",
    "3. After running the random sample through the decoder, calculate $\\mathcal{L}_{GAN}$\n",
    "\n",
    "4. Update the parameters using the gradients (see previous section)\n",
    "\n",
    "5. Note the algorithm says \"until deadline\" (we will need to define the deadline)\n",
    "\n",
    "\n",
    "**(See Figure and Algorithm on top of page 3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Parameters used in the paper\n",
    "\n",
    "- Trained with RMSProp \n",
    "- Learning rate = 3e-4\n",
    "- Batch size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts on VAEGAN_Basic_3 implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In VAEGAN class:\n",
    "\n",
    "```\n",
    "@staticmethod\n",
    "    def weighted_bce(outputs, labels):\n",
    "        mins, _ = labels.min(dim=1)\n",
    "        mask = mins != -1\n",
    "        criterion = torch.nn.BCELoss(reduction=\"sum\")\n",
    "        loss = criterion(torch.squeeze(outputs[mask]), labels[mask])\n",
    "        weights = 1\n",
    "        loss = (loss * weights).mean()\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def loss(ten_original, ten_predicted, layer_original, layer_predicted, layer_sampled, labels_original,\n",
    "             labels_predicted, labels_sampled, mus, variances, aux_out, aux_out_recon, aux_labels):\n",
    "        \"\"\"\n",
    "        :param ten_original: original images\n",
    "        :param ten_predicted:  predicted images (output of the decoder)\n",
    "        :param layer_original:  intermediate layer for original (intermediate output of the discriminator)\n",
    "        :param layer_predicted: intermediate layer for reconstructed (intermediate output of the discriminator)\n",
    "        :param labels_original: labels for original (output of the discriminator)\n",
    "        :param labels_predicted: labels for reconstructed (output of the discriminator)\n",
    "        :param labels_sampled: labels for sampled from gaussian (0,1) (output of the discriminator)\n",
    "        :param mus: tensor of means\n",
    "        :param variances: tensor of diagonals of log_variances\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        # reconstruction error, not used for the loss but useful to evaluate quality\n",
    "        nle = 0.5*(ten_original.view(len(ten_original), -1) - ten_predicted.view(len(ten_predicted), -1)) ** 2\n",
    "        \n",
    "        # kl-divergence\n",
    "        kl = -0.5 * torch.sum(-variances.exp() - torch.pow(mus,2) + variances + 1, 1)\n",
    "        \n",
    "        # mse between intermediate layers for both\n",
    "        mse_1 = torch.sum(1.0*(layer_original - layer_predicted) ** 2, 1) / 2.\n",
    "        mse_2 = torch.Tensor([0]) #torch.sum(0.5*(layer_original - layer_sampled) ** 2, 1) / 2.\n",
    "        \n",
    "        # bce for decoder and discriminator for original,sampled and reconstructed\n",
    "        # the only excluded is the bce_gen_original\n",
    "        bce_dis_original = -torch.log(labels_original + 1e-3)\n",
    "        bce_dis_sampled = -torch.log(1 - labels_sampled + 1e-3)\n",
    "        bce_dis_recon = -torch.log(1 - labels_predicted + 1e-3)\n",
    "\n",
    "        bce_gen_sampled = -torch.log(labels_sampled + 1e-3)\n",
    "        bce_gen_recon = -torch.log(labels_predicted + 1e-3)\n",
    "        \n",
    "        aux_loss_original = VaeGan.weighted_bce(aux_out, aux_labels.float())\n",
    "        \n",
    "        return nle, kl, mse_1, mse_2, bce_dis_original, bce_dis_sampled, bce_dis_recon, bce_gen_sampled, bce_gen_recon, aux_loss_original  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `nle`: not sure what this is\n",
    "- The MSE of the intermediate layers are calculated - is this a VAE measure? (These are `mse_1` and `mse_2`)\n",
    "- The gradient updates and loss calculations are done outside of the loss function - in the training script.\n",
    "- Do we need to calculate the BCE?\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# THIS IS THE MOST IMPORTANT PART OF THE CODE\n",
    "loss_encoder = torch.sum(kl_value)+torch.sum(mse_value_1) # + torch.sum(mse_value_2)\n",
    "loss_discriminator = torch.sum(bce_dis_original_value) + torch.sum(bce_dis_sampled_value) + torch.sum(bce_dis_predicted_value) + (lambda_aux * aux_loss)\n",
    "loss_decoder = torch.sum(bce_gen_sampled_value) + torch.sum(bce_gen_predicted_value)\n",
    "loss_decoder = torch.sum(lambda_mse / 1 * mse_value_1) + ((1.0 - lambda_mse) * loss_decoder)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "- https://towardsdatascience.com/variational-autoencoder-demystified-with-pytorch-implementation-3a06bee395ed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
